{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "onOeCT_HbGMC"
      },
      "source": [
        "**You must run this on a GPU. A T4 is sufficient. It's free on Google Colab.**\n",
        "\n",
        "**Description**: for a 4 GB quantized Llama 2 model, this notebook demonstrates that\n",
        "\n",
        "1. classification via sampling (CVS) is not effective\n",
        "2. CAPPr is effective; it recovers 94% of the performance of OpenAI's `gpt-3.5-turbo`,\n",
        "   and requires no post-processing of the output.\n",
        "\n",
        "**Contamination notice**: I don't know whether the Llama 2 was trained on any COPA data.\n",
        "If it was, but there's no interaction between the method (CAPPr vs CVS) and training,\n",
        "then the difference between performances can be studied.\n",
        "\n",
        "**Estimated run time**: ~6 min. (CVS is slow for this model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5H2cqyOvbGMT"
      },
      "source": [
        "[Install packages](#install-packages)\n",
        "\n",
        "[Load model and tokenizer](#load-model-and-tokenizer)\n",
        "\n",
        "[Utils](#utils)\n",
        "\n",
        "[Load data](#load-data)\n",
        "\n",
        "[The problem](#the-problem)\n",
        "\n",
        "[Write prompt](#write-prompt)\n",
        "\n",
        "[The solution](#the-solution)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3edTvevkoCCR"
      },
      "source": [
        "# Install packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-1PMxgjtbVK_"
      },
      "outputs": [],
      "source": [
        "# check correct CUDA version\n",
        "import torch\n",
        "\n",
        "_cuda_version = torch.version.cuda\n",
        "_msg = (\n",
        "    \"Change the pip install auto-gptq command to the one for \"\n",
        "    f\"{_cuda_version} based on the list here: \"\n",
        "    \"https://github.com/PanQiWei/AutoGPTQ#quick-installation\"\n",
        ")\n",
        "\n",
        "assert _cuda_version == \"11.8\", _msg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6H2ukkr1cy6Z"
      },
      "source": [
        "I don't wanna pay for renting an A100 so I need to use a semi-aggressively quantized\n",
        "model. Something which fits on a T4. Need the latest `transformers`, `auto-gptq`, and\n",
        "`optimum` according to this [HF blog\n",
        "post](https://huggingface.co/blog/gptq-integration#autogptq-library--the-one-stop-library-for-efficiently-leveraging-gptq-for-llms)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NicJ2-6Hcump"
      },
      "outputs": [],
      "source": [
        "!python -m pip install cappr[demos] \\\n",
        "transformers==4.33.0 \\\n",
        "pip install auto-gptq --extra-index-url https://huggingface.github.io/autogptq-index/whl/cu118/ \\\n",
        "optimum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "WNW0Cz1sbGMX"
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "from pprint import pprint\n",
        "from typing import Literal\n",
        "\n",
        "import datasets\n",
        "import pandas as pd\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForCausalLM,\n",
        "    pipeline,\n",
        ")\n",
        "\n",
        "from cappr import Example\n",
        "from cappr.huggingface import classify"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SV3-xk9XdLHd"
      },
      "source": [
        "# Load model and tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "0RSHAIpRdM4J"
      },
      "outputs": [],
      "source": [
        "_msg = (\n",
        "    \"This should probably be run on a GPU. A T4 instance is sufficient for the models \"\n",
        "    \"tested here.\"\n",
        ")\n",
        "assert torch.cuda.is_available(), _msg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "d1PhQnKXeLqY"
      },
      "outputs": [],
      "source": [
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "SPcTWABWdQAt"
      },
      "outputs": [],
      "source": [
        "model_id = \"TheBloke/Llama-2-7B-GPTQ\"\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id, torch_dtype=torch.float16, device_map=\"auto\"\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "K0d2_IE5dTEA"
      },
      "outputs": [],
      "source": [
        "# warm up model\n",
        "_ = model(**tokenizer([\"warm up\"], return_tensors=\"pt\").to(DEVICE))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcMpkOdlcapS"
      },
      "source": [
        "# Utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljguOue9cfcm"
      },
      "source": [
        "Copied from [here](https://github.com/kddubey/cappr/blob/main/demos/utils.py) so that this notebook can be run anywhere."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "vIdleXW_ccBH"
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "from typing import Optional, Union\n",
        "\n",
        "from IPython.display import display\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "def display_df(\n",
        "    df: pd.DataFrame,\n",
        "    columns: Optional[list[str]] = None,\n",
        "    num_rows: Union[int, None] = 3,\n",
        "):\n",
        "    \"\"\"\n",
        "    Displays `df.head(num_rows)[columns]` without truncating columns. If\n",
        "    possible, render any newlines.\n",
        "    \"\"\"\n",
        "    if columns is None:\n",
        "        columns = df.columns\n",
        "    if num_rows is None:\n",
        "        num_rows = len(df)\n",
        "    df_head_styled = df.head(num_rows)[columns].style\n",
        "    with pd.option_context(\"max_colwidth\", -1):\n",
        "        # I'm not sure why try-except doesn't work w/ display(), so instead\n",
        "        # check the necessary uniqueness condition before running it\n",
        "        if df.index.is_unique:\n",
        "            display(\n",
        "                df_head_styled.set_properties(\n",
        "                    **{\"text-align\": \"left\", \"white-space\": \"pre-wrap\"}\n",
        "                )\n",
        "            )\n",
        "        else:\n",
        "            # `Styler.apply` and `.applymap` are not compatible with non-unique\n",
        "            # index or columns\n",
        "            display(df_head_styled)\n",
        "\n",
        "\n",
        "def remove_suffix(string: str, suffix: str):\n",
        "    if string.endswith(suffix):\n",
        "        return string[: -len(suffix)]\n",
        "    return string\n",
        "\n",
        "\n",
        "def remove_prefix(string: str, prefix: str) -> str:\n",
        "    if string.startswith(prefix):\n",
        "        return string[len(prefix) :]\n",
        "    return string"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OcCXl84vbGMd"
      },
      "source": [
        "# Load data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8cYXqVubGMe"
      },
      "source": [
        "For this MVP, let's evaluate on the [Choice of Plausible Alternatives (COPA) task](https://people.ict.usc.edu/~gordon/copa.html). I picked this first b/c I read it has multi-token labels, in some sense. It also looks cool.\n",
        "\n",
        "The classification problem is to pick 1 of 2 alternatives which caused or resulted in the premise. Here are two example pulled from the website:\n",
        "\n",
        "Example 1\n",
        "\n",
        "> Premise: The man broke his toe. What was the CAUSE of this?\n",
        ">\n",
        "> Alternative 1: He got a hole in his sock.\n",
        ">\n",
        "> Alternative 2: He dropped a hammer on his foot.\n",
        "\n",
        "\n",
        "Example 2\n",
        "\n",
        "> Premise: I tipped the bottle. What happened as a RESULT?\n",
        ">\n",
        "> Alternative 1: The liquid in the bottle froze.\n",
        ">\n",
        "> Alternative 2: The liquid in the bottle poured out.\n",
        "\n",
        "A classifier should predict Alternative 2 for Example 1, and Alternative 2 for Example 2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfcnx1mbbGMi"
      },
      "source": [
        "The test set labels are hidden, so I'll score this zero-shot classifier on the train and validation sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "0WayD0g5bGMj"
      },
      "outputs": [],
      "source": [
        "def load_super_glue(task_id: str, split: str):\n",
        "    return pd.DataFrame(datasets\n",
        "                        .load_dataset('super_glue', task_id, split=split))\n",
        "\n",
        "\n",
        "# takes about 12 seconds\n",
        "df = (pd.concat((load_super_glue('copa', 'train'),\n",
        "                 load_super_glue('copa', 'validation')))\n",
        "      .reset_index(drop=True)) # idx column is only unique w/in splits! fuhgetaboutit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AlOIxn66bGMm",
        "outputId": "48f05d92-e903-4030-a003-60be17728f1d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "500"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "8UYnBCHtbGNH",
        "outputId": "2e14a4e5-53a6-4417-a13c-367fe19a0640"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-c13f6a93-0044-4d27-ac52-0b2500c8b5ad\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>premise</th>\n",
              "      <th>choice1</th>\n",
              "      <th>choice2</th>\n",
              "      <th>question</th>\n",
              "      <th>idx</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>My body cast a shadow over the grass.</td>\n",
              "      <td>The sun was rising.</td>\n",
              "      <td>The grass was cut.</td>\n",
              "      <td>cause</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The woman tolerated her friend's difficult beh...</td>\n",
              "      <td>The woman knew her friend was going through a ...</td>\n",
              "      <td>The woman felt that her friend took advantage ...</td>\n",
              "      <td>cause</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The women met for coffee.</td>\n",
              "      <td>The cafe reopened in a new location.</td>\n",
              "      <td>They wanted to catch up with each other.</td>\n",
              "      <td>cause</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The runner wore shorts.</td>\n",
              "      <td>The forecast predicted high temperatures.</td>\n",
              "      <td>She planned to run along the beach.</td>\n",
              "      <td>cause</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The guests of the party hid behind the couch.</td>\n",
              "      <td>It was a surprise party.</td>\n",
              "      <td>It was a birthday party.</td>\n",
              "      <td>cause</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c13f6a93-0044-4d27-ac52-0b2500c8b5ad')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c13f6a93-0044-4d27-ac52-0b2500c8b5ad button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c13f6a93-0044-4d27-ac52-0b2500c8b5ad');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d0525315-da81-4768-ab43-fe790c148705\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d0525315-da81-4768-ab43-fe790c148705')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d0525315-da81-4768-ab43-fe790c148705 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                             premise  \\\n",
              "0              My body cast a shadow over the grass.   \n",
              "1  The woman tolerated her friend's difficult beh...   \n",
              "2                          The women met for coffee.   \n",
              "3                            The runner wore shorts.   \n",
              "4      The guests of the party hid behind the couch.   \n",
              "\n",
              "                                             choice1  \\\n",
              "0                                The sun was rising.   \n",
              "1  The woman knew her friend was going through a ...   \n",
              "2               The cafe reopened in a new location.   \n",
              "3          The forecast predicted high temperatures.   \n",
              "4                           It was a surprise party.   \n",
              "\n",
              "                                             choice2 question  idx  label  \n",
              "0                                 The grass was cut.    cause    0      0  \n",
              "1  The woman felt that her friend took advantage ...    cause    1      0  \n",
              "2           They wanted to catch up with each other.    cause    2      1  \n",
              "3                She planned to run along the beach.    cause    3      0  \n",
              "4                           It was a birthday party.    cause    4      0  "
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgNUWO0ZbGNv"
      },
      "source": [
        "# The problem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l58CPJ32qucO"
      },
      "source": [
        "The most straightforward way to solve this task is to point to each alternative with a single letter, and hope that the LM samples/generates the correct letter. The prompt is effectively a multiple choice question. This approach falls under the umbrella of \"classification via sampling\" (CVS)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QowIM4eJbGN0"
      },
      "source": [
        "For example:\n",
        "\n",
        "```\n",
        "The man broke his toe because\n",
        "A. He got a hole in his sock.\n",
        "B. He dropped a hammer on his foot.\n",
        "Answer A or B.\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "PDtZShBKteyZ"
      },
      "outputs": [],
      "source": [
        "def _conjunction(question: Literal[\"cause\", \"effect\"]):\n",
        "    if question == \"cause\":\n",
        "        return \" because\"\n",
        "    elif question == \"effect\":\n",
        "        return \", so\"\n",
        "    else:\n",
        "        raise ValueError(\"question must be 'cause' or 'effect'. Got \" f\"{question}.\")\n",
        "\n",
        "\n",
        "def prompt(premise: str, question: Literal[\"cause\", \"effect\"]):\n",
        "    conjunction = _conjunction(question)\n",
        "    return f'{premise.strip(\". \")}{conjunction}'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "7RUrWpZNbGN1",
        "outputId": "3fe58ef7-fa5a-4740-d5b4-711b79e71832"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_c6976_row0_col0, #T_c6976_row0_col1, #T_c6976_row1_col0, #T_c6976_row1_col1, #T_c6976_row2_col0, #T_c6976_row2_col1 {\n",
              "  text-align: left;\n",
              "  white-space: pre-wrap;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_c6976\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_c6976_level0_col0\" class=\"col_heading level0 col0\" >prompt_mc</th>\n",
              "      <th id=\"T_c6976_level0_col1\" class=\"col_heading level0 col1\" >label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_c6976_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "      <td id=\"T_c6976_row0_col0\" class=\"data row0 col0\" >My body cast a shadow over the grass because\n",
              "A. The sun was rising.\n",
              "B. The grass was cut.\n",
              "Answer A or B.</td>\n",
              "      <td id=\"T_c6976_row0_col1\" class=\"data row0 col1\" >0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_c6976_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "      <td id=\"T_c6976_row1_col0\" class=\"data row1 col0\" >The woman tolerated her friend's difficult behavior because\n",
              "A. The woman knew her friend was going through a hard time.\n",
              "B. The woman felt that her friend took advantage of her kindness.\n",
              "Answer A or B.</td>\n",
              "      <td id=\"T_c6976_row1_col1\" class=\"data row1 col1\" >0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_c6976_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "      <td id=\"T_c6976_row2_col0\" class=\"data row2 col0\" >The women met for coffee because\n",
              "A. The cafe reopened in a new location.\n",
              "B. They wanted to catch up with each other.\n",
              "Answer A or B.</td>\n",
              "      <td id=\"T_c6976_row2_col1\" class=\"data row2 col1\" >1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7db7c0fe4cd0>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def prompt_mc(\n",
        "    premise: str, question: Literal[\"cause\", \"effect\"], choice1: str, choice2: str\n",
        "):\n",
        "    return (\n",
        "        f\"{prompt(premise, question)}\\n\"\n",
        "        f\"A. {choice1}\\n\"\n",
        "        f\"B. {choice2}\\n\"\n",
        "        \"Answer A or B.\"\n",
        "    )\n",
        "\n",
        "\n",
        "df[\"prompt_mc\"] = [\n",
        "    prompt_mc(\n",
        "        record[\"premise\"], record[\"question\"], record[\"choice1\"], record[\"choice2\"]\n",
        "    )\n",
        "    for record in df.to_dict(\"records\")\n",
        "]\n",
        "\n",
        "\n",
        "display_df(df, columns=[\"prompt_mc\", \"label\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFuoUoBkbGOO"
      },
      "source": [
        "(It turns out that GitHub doesn't render the newlines, but I promise they're there!)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_OaEEYAbrVf7"
      },
      "source": [
        "Set up a huggingface text generator:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "GrjxsXQXhswC"
      },
      "outputs": [],
      "source": [
        "generator = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model_id,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "# pad to allow batching. these get masked out ofc\n",
        "generator.tokenizer.pad_token_id = generator.model.config.eos_token_id"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YyWmSO6wiSHd"
      },
      "source": [
        "We need to create a PyTorch Dataset to batch the inputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "UCDR9dZQiQ_e"
      },
      "outputs": [],
      "source": [
        "class TextsDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, texts: list[str]):\n",
        "        self.texts = texts\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, index: int):\n",
        "        return self.texts[index]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "zPgR4zI7hxNE"
      },
      "outputs": [],
      "source": [
        "sequences = generator(\n",
        "    TextsDataset(df[\"prompt_mc\"].tolist()),\n",
        "    do_sample=True,\n",
        "    num_return_sequences=1,\n",
        "    top_k=50,\n",
        "    eos_token_id=tokenizer.eos_token_id,\n",
        "    max_new_tokens=10,\n",
        "    batch_size=1,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-tZAkC5tkjBz"
      },
      "source": [
        "Welp, setting `batch_size` > 1 causes numerical errors. This next cell is gonna take ~5 min :-("
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "83cf14e4d66140b9824c7c08a09ca95a",
            "21dc4a0700fa45ed88777bf139311cd0",
            "97bc6107e437471a971c3cf3626d29fa",
            "30efc345a2604824a3dcd24ef38cfd77",
            "96f90b54d47c49d7bc0d7fbd19810c1b",
            "93952dc3a5314c66b7626596976a515b",
            "b4f06dff405942b983463feb2dde6472",
            "902c5eb0b0f144738b8c57dc982adb3d",
            "17a08f00cef64299bdb50e8474832347",
            "812736a2a8e14ad28f511b1590dc719c",
            "2bd4270b573543d0b5e86ae21364f05f"
          ]
        },
        "id": "V1J5uu1wjGsH",
        "outputId": "90f2a717-4377-4fe8-9648-965f595e107b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "83cf14e4d66140b9824c7c08a09ca95a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Sampling:   0%|          | 0/500 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1417: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "responses = []\n",
        "for seq in tqdm(sequences, total=len(df), desc=\"Sampling\"):\n",
        "    responses.append(seq[0][\"generated_text\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "OqrgRIiQjzPW"
      },
      "outputs": [],
      "source": [
        "responses_cleaned = [\n",
        "    remove_prefix(response, prompt_mc)\n",
        "    for prompt_mc, response in zip(df[\"prompt_mc\"], responses)\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMtKqqdPlggb",
        "outputId": "9ca6c3e5-f477-4d4a-f5bc-b7b26b58bbd8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "123                                    [2x3=6] Note: The\n",
              "112               When in doubt, trust your instinct.\\nA\n",
              "278        \\nIf an individual has been hired temporarily\n",
              "172             \\n9. Many people are of the opinion that\n",
              "36            We know all, but a is more appropriate for\n",
              "310                          \\n1. We can’t have any more\n",
              "474                                          \\n(1) 30.04\n",
              "97                   \\nIf the speaker says, “Do you know\n",
              "330                       \\nC. This is a test and is not\n",
              "318     Please note that answers\\nshould not be a mix...\n",
              "dtype: object"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.Series(responses_cleaned).sample(n=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzDVVD1bmMEi"
      },
      "source": [
        "For this relatively tame dataset, only a fraction of the LM's responses contain a letter which is easy to parse. Computing acccuracy is kind of pointless; we don't even have real predictions.\n",
        "\n",
        "Unfortunately, for smaller or less-instruction-trained LMs, CVS can raise more problems than it solves. This result aligns with the one found in the [demo for `text-curie-001`](https://github.com/kddubey/cappr/blob/main/demos/superglue/copa.ipynb); sampling structured outputs from smaller language models is not statistically performant.\n",
        "\n",
        "What do we do?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YwqNyZSqbGNJ"
      },
      "source": [
        "# Write prompt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ECMyLwrVprBh"
      },
      "source": [
        "We should take advantage of the fact that models like Llama 2 were extensively trained for a simple task: predict the next token."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Io8zpoLibGNK"
      },
      "source": [
        "A simple way to model COPA is to prompt an LM with (for Example 1):\n",
        "\n",
        "```\n",
        "The man broke his toe because\n",
        "```\n",
        "\n",
        "and use the LM to estimate the probabilities of the 2 alternatives conditional on this prompt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "0xlrUCdJbGNT"
      },
      "outputs": [],
      "source": [
        "df[\"prompt\"] = [\n",
        "    prompt(premise, question)\n",
        "    for premise, question in zip(df[\"premise\"], df[\"question\"])\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "6zH9PPBpbGNd",
        "outputId": "a0ab1770-d865-4287-b783-62b88941179b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_50547_row0_col0, #T_50547_row0_col1, #T_50547_row0_col2, #T_50547_row0_col3, #T_50547_row1_col0, #T_50547_row1_col1, #T_50547_row1_col2, #T_50547_row1_col3, #T_50547_row2_col0, #T_50547_row2_col1, #T_50547_row2_col2, #T_50547_row2_col3 {\n",
              "  text-align: left;\n",
              "  white-space: pre-wrap;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_50547\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_50547_level0_col0\" class=\"col_heading level0 col0\" >prompt</th>\n",
              "      <th id=\"T_50547_level0_col1\" class=\"col_heading level0 col1\" >choice1</th>\n",
              "      <th id=\"T_50547_level0_col2\" class=\"col_heading level0 col2\" >choice2</th>\n",
              "      <th id=\"T_50547_level0_col3\" class=\"col_heading level0 col3\" >label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_50547_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "      <td id=\"T_50547_row0_col0\" class=\"data row0 col0\" >My body cast a shadow over the grass because</td>\n",
              "      <td id=\"T_50547_row0_col1\" class=\"data row0 col1\" >The sun was rising.</td>\n",
              "      <td id=\"T_50547_row0_col2\" class=\"data row0 col2\" >The grass was cut.</td>\n",
              "      <td id=\"T_50547_row0_col3\" class=\"data row0 col3\" >0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_50547_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "      <td id=\"T_50547_row1_col0\" class=\"data row1 col0\" >The woman tolerated her friend's difficult behavior because</td>\n",
              "      <td id=\"T_50547_row1_col1\" class=\"data row1 col1\" >The woman knew her friend was going through a hard time.</td>\n",
              "      <td id=\"T_50547_row1_col2\" class=\"data row1 col2\" >The woman felt that her friend took advantage of her kindness.</td>\n",
              "      <td id=\"T_50547_row1_col3\" class=\"data row1 col3\" >0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_50547_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "      <td id=\"T_50547_row2_col0\" class=\"data row2 col0\" >The women met for coffee because</td>\n",
              "      <td id=\"T_50547_row2_col1\" class=\"data row2 col1\" >The cafe reopened in a new location.</td>\n",
              "      <td id=\"T_50547_row2_col2\" class=\"data row2 col2\" >They wanted to catch up with each other.</td>\n",
              "      <td id=\"T_50547_row2_col3\" class=\"data row2 col3\" >1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7db7c06b5990>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display_df(df, columns=[\"prompt\", \"choice1\", \"choice2\", \"label\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFzKox8RbGNe"
      },
      "source": [
        "Note: we need to lowercase the choices."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHgGqHrKbGNe"
      },
      "source": [
        "# The solution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qy6mp0MnpHVG"
      },
      "source": [
        "Also observe that the interface feels simpler than HuggingFace's pipeline generation, as they have to worry about so many more things when sampling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "XhJ8a7LsbGNn"
      },
      "outputs": [],
      "source": [
        "examples = [\n",
        "    Example(\n",
        "        prompt=record[\"prompt\"],\n",
        "        completions=(record[\"choice1\"].lower(), record[\"choice2\"].lower()),\n",
        "        prior=None,\n",
        "    )\n",
        "    for record in df.to_dict(\"records\")\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOWsFSuzegqp",
        "outputId": "5830919e-ab27-4dc8-9fdb-7456182df98d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Example(prompt='My body cast a shadow over the grass because',\n",
            "        completions=('the sun was rising.', 'the grass was cut.'),\n",
            "        prior=None,\n",
            "        end_of_prompt=' ')\n"
          ]
        }
      ],
      "source": [
        "pprint(examples[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsz0rX0CbGNq"
      },
      "source": [
        "We have 500 examples * 2 classes = 1000 model inferences. Set the batch size to something that'll work on your machine. On a T4, `batch_size = 32` works for this data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "OqpcpI3cl525"
      },
      "outputs": [],
      "source": [
        "batch_size = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "1fc12dabf1744ba289ca86af50c66f5c",
            "c11b2df80d3e44cb975d4f4cf95befdd",
            "08182afa48e34bb7b69fba974b8f3401",
            "e96dd6bf3de04ff691f2e8fca940ecd7",
            "51a60584a374480fa935633bfc1ce49b",
            "160a733760b0444689ee8c5a241ef8b2",
            "4e5d78597fbc4d02a2d5be3215bd88d5",
            "a131ddd3f2134b4590376b327aa83e72",
            "d61e56a038554c7dbf4016ce04b5ef4f",
            "96bdf406e16b44f5be6b67b0fb919467",
            "bf9164564df94c5fa887c8b8b0947083"
          ]
        },
        "id": "HB0Rda7rbGNq",
        "outputId": "df7f3330-2b81-41f4-f6f2-6beec6d00c27"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1fc12dabf1744ba289ca86af50c66f5c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "log-probs:   0%|          | 0/500 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/cappr/utils/classify.py:63: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  np.array(  # raises jagged/inhomogeneous ValueError if non-constant # tokens\n"
          ]
        }
      ],
      "source": [
        "pred_probs = classify.predict_proba_examples(\n",
        "    examples, model_and_tokenizer=(model, tokenizer), batch_size=batch_size\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXDHf0uPbGNr"
      },
      "source": [
        "For COPA, the scoring metric is accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QVxgmQkwbGNr",
        "outputId": "6af42ce2-31eb-46b0-9160-2be0bdc00de2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.816"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(pred_probs.argmax(axis=1) == df[\"label\"]).mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYOh3hpZgkHx"
      },
      "source": [
        "This 4 GB open source model beats OpenAI's `text-curie-001`, which was 80% accurate according to the CAPPr demo [here](https://github.com/kddubey/cappr/blob/main/demos/superglue/copa.ipynb). OpenAI's `gpt-3.5-turbo` is 86.6% accurate. So we've recovered 94% of its performance by using CAPPr. Ha."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "68daa88f78f5c448099edb3a6d3dee27486a6add8824ae1cbe4c903ef8faec70"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "08182afa48e34bb7b69fba974b8f3401": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a131ddd3f2134b4590376b327aa83e72",
            "max": 500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d61e56a038554c7dbf4016ce04b5ef4f",
            "value": 500
          }
        },
        "160a733760b0444689ee8c5a241ef8b2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17a08f00cef64299bdb50e8474832347": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1fc12dabf1744ba289ca86af50c66f5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c11b2df80d3e44cb975d4f4cf95befdd",
              "IPY_MODEL_08182afa48e34bb7b69fba974b8f3401",
              "IPY_MODEL_e96dd6bf3de04ff691f2e8fca940ecd7"
            ],
            "layout": "IPY_MODEL_51a60584a374480fa935633bfc1ce49b"
          }
        },
        "21dc4a0700fa45ed88777bf139311cd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_93952dc3a5314c66b7626596976a515b",
            "placeholder": "​",
            "style": "IPY_MODEL_b4f06dff405942b983463feb2dde6472",
            "value": "Sampling: 100%"
          }
        },
        "2bd4270b573543d0b5e86ae21364f05f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "30efc345a2604824a3dcd24ef38cfd77": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_812736a2a8e14ad28f511b1590dc719c",
            "placeholder": "​",
            "style": "IPY_MODEL_2bd4270b573543d0b5e86ae21364f05f",
            "value": " 500/500 [05:07&lt;00:00,  1.95it/s]"
          }
        },
        "4e5d78597fbc4d02a2d5be3215bd88d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "51a60584a374480fa935633bfc1ce49b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "812736a2a8e14ad28f511b1590dc719c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83cf14e4d66140b9824c7c08a09ca95a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_21dc4a0700fa45ed88777bf139311cd0",
              "IPY_MODEL_97bc6107e437471a971c3cf3626d29fa",
              "IPY_MODEL_30efc345a2604824a3dcd24ef38cfd77"
            ],
            "layout": "IPY_MODEL_96f90b54d47c49d7bc0d7fbd19810c1b"
          }
        },
        "902c5eb0b0f144738b8c57dc982adb3d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93952dc3a5314c66b7626596976a515b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96bdf406e16b44f5be6b67b0fb919467": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96f90b54d47c49d7bc0d7fbd19810c1b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97bc6107e437471a971c3cf3626d29fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_902c5eb0b0f144738b8c57dc982adb3d",
            "max": 500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_17a08f00cef64299bdb50e8474832347",
            "value": 500
          }
        },
        "a131ddd3f2134b4590376b327aa83e72": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4f06dff405942b983463feb2dde6472": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bf9164564df94c5fa887c8b8b0947083": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c11b2df80d3e44cb975d4f4cf95befdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_160a733760b0444689ee8c5a241ef8b2",
            "placeholder": "​",
            "style": "IPY_MODEL_4e5d78597fbc4d02a2d5be3215bd88d5",
            "value": "log-probs: 100%"
          }
        },
        "d61e56a038554c7dbf4016ce04b5ef4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e96dd6bf3de04ff691f2e8fca940ecd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96bdf406e16b44f5be6b67b0fb919467",
            "placeholder": "​",
            "style": "IPY_MODEL_bf9164564df94c5fa887c8b8b0947083",
            "value": " 500/500 [00:16&lt;00:00, 28.56it/s]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
