{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Description**: demonstrates that the zero-shot text classification method [described here](https://stats.stackexchange.com/q/601159/337906) works well on the [Winograd Schema Challenge (WSC)](https://cs.nyu.edu/~davise/papers/WinogradSchemas/WS.html). It's one of the [SuperGLUE tasks](https://super.gluebenchmark.com/tasks) in which labels have multiple tokens, in some sense.\n",
    "\n",
    "**Estimated run time**: ~1 min.\n",
    "\n",
    "**Environment**: See the [Setup section in the README](https://github.com/kddubey/lm-classification/#setup).\n",
    "\n",
    "**Other**: You have to have an OpenAI API key stored in the environment variable `OPENAI_API_KEY`. [Sign up here](https://openai.com/api/). This notebook will warn you about cost before incurring any. It'll cost ya about <span>$</span>0.30."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Load data](#load-data)\n",
    "\n",
    "[Write prompt](#write-prompt)\n",
    "\n",
    "[Run model](#run-model)\n",
    "\n",
    "[Score](#score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "import datasets as nlp_datasets\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from lm_classification import classify\n",
    "from lm_classification.utils import gpt2_tokenizer, batch_variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## When hitting the OpenAI endpoints, we'll log any server errors\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    handlers=[logging.StreamHandler(stream=sys.stdout)],\n",
    "                    format='%(asctime)s :: %(name)s :: %(levelname)s :: '\n",
    "                           '%(message)s')\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a passage with a (marked) ambiguous pronoun, the classification problem is to pick 1 of 2 alternatives which the pronoun refers to. \n",
    "\n",
    "See the [example on the website](https://cs.nyu.edu/~davise/papers/WinogradSchemas/WS.html). It's pretty cool."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test set labels are hidden, so I'll score this zero-shot classifier on the 273 examples in the `wsc273` subset of the challenge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-24 02:19:36,140 :: datasets.builder :: WARNING :: Found cached dataset winograd_wsc (C:/Users/kushd/.cache/huggingface/datasets/winograd_wsc/wsc273/0.0.0/0651311f3b6dda14889d9a063030a02458395ee50ab9f41cca4cd5a89c0c3dce)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 167.11it/s]\n"
     ]
    }
   ],
   "source": [
    "wsc_df: pd.DataFrame = (nlp_datasets\n",
    "                        .load_dataset('winograd_wsc', 'wsc273') ## TODO: idk what the subsets are\n",
    "                        ['test'] ## only available split\n",
    "                        .data.to_pandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "273"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wsc_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>pronoun</th>\n",
       "      <th>pronoun_loc</th>\n",
       "      <th>quote</th>\n",
       "      <th>quote_loc</th>\n",
       "      <th>options</th>\n",
       "      <th>label</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The city councilmen refused the demonstrators ...</td>\n",
       "      <td>they</td>\n",
       "      <td>63</td>\n",
       "      <td>they feared violence</td>\n",
       "      <td>63</td>\n",
       "      <td>[The city councilmen, The demonstrators]</td>\n",
       "      <td>0</td>\n",
       "      <td>(Winograd 1972)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The city councilmen refused the demonstrators ...</td>\n",
       "      <td>they</td>\n",
       "      <td>63</td>\n",
       "      <td>they advocated violence</td>\n",
       "      <td>63</td>\n",
       "      <td>[The city councilmen, The demonstrators]</td>\n",
       "      <td>1</td>\n",
       "      <td>(Winograd 1972)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The trophy doesn't fit into the brown suitcase...</td>\n",
       "      <td>it</td>\n",
       "      <td>55</td>\n",
       "      <td>it is too large</td>\n",
       "      <td>55</td>\n",
       "      <td>[the trophy, the suitcase]</td>\n",
       "      <td>0</td>\n",
       "      <td>Hector Levesque</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The trophy doesn't fit into the brown suitcase...</td>\n",
       "      <td>it</td>\n",
       "      <td>55</td>\n",
       "      <td>it is too small</td>\n",
       "      <td>55</td>\n",
       "      <td>[the trophy, the suitcase]</td>\n",
       "      <td>1</td>\n",
       "      <td>Hector Levesque</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Joan made sure to thank Susan for all the help...</td>\n",
       "      <td>she</td>\n",
       "      <td>47</td>\n",
       "      <td>she had received</td>\n",
       "      <td>47</td>\n",
       "      <td>[Joan, Susan]</td>\n",
       "      <td>0</td>\n",
       "      <td>Hector Levesque</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text pronoun  pronoun_loc  \\\n",
       "0  The city councilmen refused the demonstrators ...    they           63   \n",
       "1  The city councilmen refused the demonstrators ...    they           63   \n",
       "2  The trophy doesn't fit into the brown suitcase...      it           55   \n",
       "3  The trophy doesn't fit into the brown suitcase...      it           55   \n",
       "4  Joan made sure to thank Susan for all the help...     she           47   \n",
       "\n",
       "                     quote  quote_loc  \\\n",
       "0     they feared violence         63   \n",
       "1  they advocated violence         63   \n",
       "2          it is too large         55   \n",
       "3          it is too small         55   \n",
       "4         she had received         47   \n",
       "\n",
       "                                    options  label           source  \n",
       "0  [The city councilmen, The demonstrators]      0  (Winograd 1972)  \n",
       "1  [The city councilmen, The demonstrators]      1  (Winograd 1972)  \n",
       "2                [the trophy, the suitcase]      0  Hector Levesque  \n",
       "3                [the trophy, the suitcase]      1  Hector Levesque  \n",
       "4                             [Joan, Susan]      0  Hector Levesque  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wsc_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write prompt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method we'll use is described in [this paper](https://arxiv.org/abs/1806.02847)<sup>1</sup>. See Table 1. We'll do the \"partial\" method b/c the authors demonstrate that it performs better. The idea there is super similar (if not identical) to the motivation behind this package. In fact, section 3.4 of the [GPT-3 paper](https://arxiv.org/abs/2005.14165)<sup>2</sup> doesn't actually use sampling for WSC! It uses the same partial method. I guess my algorithm isn't so novel after all, heh.\n",
    "\n",
    "1. Trinh, Trieu H., and Quoc V. Le. \"A simple method for commonsense reasoning.\" arXiv preprint arXiv:1806.02847 (2018).\n",
    "\n",
    "2. Brown, Tom, et al. \"Language models are few-shot learners.\" Advances in neural information processing systems 33 (2020): 1877-1901."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create the partial prompts and their completions, I'll just take some of the code from [here](https://github.com/EleutherAI/lm-evaluation-harness/blob/master/lm_eval/tasks/wsc273.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "_upper_pronouns = [\"A\",\"An\",\"The\",\"She\",\"He\",\"It\",\"They\",\"My\",\"His\",\"Her\",\"Their\"]\n",
    "\n",
    "\n",
    "def _normalize_option(doc, option):\n",
    "    # Append `'s` to possessive determiner based options.\n",
    "    if doc[\"pronoun\"].lower() in [\"my\", \"his\", \"her\", \"our\", \"their\"]:\n",
    "        option += \"'s\"\n",
    "    # Appropriately lowercase the pronoun in the option.\n",
    "    pronoun = option.split()[0]\n",
    "    start_of_sentence = doc[\"text\"][doc[\"pronoun_loc\"] - 2] == \".\"\n",
    "    if not start_of_sentence and pronoun in _upper_pronouns:\n",
    "        return option.replace(pronoun, pronoun.lower())\n",
    "    return option\n",
    "\n",
    "\n",
    "def _process_doc(doc):\n",
    "    # The HF implementation of `wsc273` is not `partial evaluation` friendly.\n",
    "    doc[\"text\"] = doc[\"text\"].replace(\"  \", \" \")\n",
    "    doc[\"options\"][0] = _normalize_option(doc, doc[\"options\"][0])\n",
    "    doc[\"options\"][1] = _normalize_option(doc, doc[\"options\"][1])\n",
    "    return doc\n",
    "\n",
    "\n",
    "def partial_context(doc, option):\n",
    "    # Substitute the pronoun in the original text with the specified\n",
    "    # option and ignore everything after.\n",
    "    return doc[\"text\"][: doc[\"pronoun_loc\"]] + option\n",
    "\n",
    "\n",
    "def partial_target(doc):\n",
    "    # The target is everything after the document specified pronoun.\n",
    "    start_index = doc[\"pronoun_loc\"] + len(doc[\"pronoun\"])\n",
    "    return \" \" + doc[\"text\"][start_index:].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "wsc_exploded_df = (pd.DataFrame([_process_doc(doc)\n",
    "                                 for doc in wsc_df.to_dict('records')])\n",
    "                   .explode(column='options')\n",
    "                   .rename(columns={'options': 'option'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "wsc_exploded_df['prompt'] = [partial_context(doc, option)\n",
    "                             for doc, option\n",
    "                             in zip(wsc_exploded_df.to_dict('records'),\n",
    "                                    wsc_exploded_df['option'])]\n",
    "wsc_exploded_df['completion'] = [partial_target(doc)\n",
    "                                 for doc in wsc_exploded_df.to_dict('records')]\n",
    "## just in case\n",
    "wsc_exploded_df['prompt'] = wsc_exploded_df['prompt'].str.strip()\n",
    "wsc_exploded_df['completion'] = wsc_exploded_df['completion'].str.strip()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the first 4 examples (8 records in the exploded df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>completion</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The city councilmen refused the demonstrators a permit because the city councilmen</td>\n",
       "      <td>feared violence.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The city councilmen refused the demonstrators a permit because the demonstrators</td>\n",
       "      <td>feared violence.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The city councilmen refused the demonstrators a permit because the city councilmen</td>\n",
       "      <td>advocated violence.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The city councilmen refused the demonstrators a permit because the demonstrators</td>\n",
       "      <td>advocated violence.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The trophy doesn't fit into the brown suitcase because the trophy</td>\n",
       "      <td>is too large.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The trophy doesn't fit into the brown suitcase because the suitcase</td>\n",
       "      <td>is too large.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The trophy doesn't fit into the brown suitcase because the trophy</td>\n",
       "      <td>is too small.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The trophy doesn't fit into the brown suitcase because the suitcase</td>\n",
       "      <td>is too small.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                               prompt  \\\n",
       "0  The city councilmen refused the demonstrators a permit because the city councilmen   \n",
       "0  The city councilmen refused the demonstrators a permit because the demonstrators     \n",
       "1  The city councilmen refused the demonstrators a permit because the city councilmen   \n",
       "1  The city councilmen refused the demonstrators a permit because the demonstrators     \n",
       "2  The trophy doesn't fit into the brown suitcase because the trophy                    \n",
       "2  The trophy doesn't fit into the brown suitcase because the suitcase                  \n",
       "3  The trophy doesn't fit into the brown suitcase because the trophy                    \n",
       "3  The trophy doesn't fit into the brown suitcase because the suitcase                  \n",
       "\n",
       "            completion  label  \n",
       "0  feared violence.     0      \n",
       "0  feared violence.     0      \n",
       "1  advocated violence.  1      \n",
       "1  advocated violence.  1      \n",
       "2  is too large.        0      \n",
       "2  is too large.        0      \n",
       "3  is too small.        1      \n",
       "3  is too small.        1      "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_num_examples_displayed = 2 * 4\n",
    "with pd.option_context('max_colwidth', -1):\n",
    "    display(wsc_exploded_df\n",
    "            [['prompt', 'completion', 'label']]\n",
    "            .head(_num_examples_displayed))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I was dubious about how well the code worked, so I scanned more examples. There's a potential problem with the 54th example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>option</th>\n",
       "      <th>prompt</th>\n",
       "      <th>completion</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>the gap</td>\n",
       "      <td>There is a gap in the wall. You can see the garden through the gap</td>\n",
       "      <td>.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>the wall</td>\n",
       "      <td>There is a gap in the wall. You can see the garden through the wall</td>\n",
       "      <td>.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      option  \\\n",
       "54  the gap    \n",
       "54  the wall   \n",
       "\n",
       "                                                                 prompt  \\\n",
       "54  There is a gap in the wall. You can see the garden through the gap    \n",
       "54  There is a gap in the wall. You can see the garden through the wall   \n",
       "\n",
       "   completion  label  \n",
       "54  .          0      \n",
       "54  .          0      "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with pd.option_context('max_colwidth', -1):\n",
    "    display(wsc_exploded_df\n",
    "            [['option', 'prompt', 'completion', 'label']]\n",
    "            .loc[54])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how many examples have this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_mask_corrupt = wsc_exploded_df['completion'] == '.'\n",
    "sum(_mask_corrupt) / 2 ## in the expoded df, there are 2 records per example"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like a systematic issue we need to correct. The problem is that computing Pr('.' | prompt) for these wouldn't discriminate at all. The `option` does discriminate. So let's just take the `option` out of the `prompt` and move it to the `completion`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "_mask_corrupt = wsc_exploded_df['completion'] == '.'\n",
    "_wsc_corrupt = wsc_exploded_df.copy()[_mask_corrupt]\n",
    "assert all(prompt.endswith(option)\n",
    "           for prompt, option\n",
    "           in zip(_wsc_corrupt['prompt'], _wsc_corrupt['option']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "_prompts_fixed = [prompt.removesuffix(option)\n",
    "                  for prompt, option\n",
    "                  in zip(_wsc_corrupt['prompt'], _wsc_corrupt['option'])]\n",
    "_completions_fixed = wsc_exploded_df.loc[_mask_corrupt, 'option']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "wsc_exploded_df.loc[_mask_corrupt, 'prompt']     = _prompts_fixed\n",
    "wsc_exploded_df.loc[_mask_corrupt, 'completion'] = _completions_fixed\n",
    "\n",
    "## just in case\n",
    "wsc_exploded_df['prompt']     = wsc_exploded_df['prompt'].str.strip()\n",
    "wsc_exploded_df['completion'] = wsc_exploded_df['completion'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>option</th>\n",
       "      <th>prompt</th>\n",
       "      <th>completion</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>the gap</td>\n",
       "      <td>There is a gap in the wall. You can see the garden through</td>\n",
       "      <td>the gap</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>the wall</td>\n",
       "      <td>There is a gap in the wall. You can see the garden through</td>\n",
       "      <td>the wall</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      option                                                      prompt  \\\n",
       "54  the gap   There is a gap in the wall. You can see the garden through   \n",
       "54  the wall  There is a gap in the wall. You can see the garden through   \n",
       "\n",
       "   completion  label  \n",
       "54  the gap    0      \n",
       "54  the wall   0      "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with pd.option_context('max_colwidth', -1):\n",
    "    display(wsc_exploded_df\n",
    "            [['option', 'prompt', 'completion', 'label']]\n",
    "            .loc[54])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There, all better."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For WSC, the probability distribution over classes (alternative 1, 2 for COPA) is uniform. So we'll use `prior=None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "wsc_examples = [classify.Example(prompt=record['prompt'],\n",
    "                                 completions=(record['completion'],),\n",
    "                                 prior=None)\n",
    "                for record in wsc_exploded_df.to_dict('records')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "546"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wsc_examples)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next cell warns you about price, and asks if you're ready to pay.\n",
    "\n",
    "(small TODO: I forgot what `input` does in Jupyter notebooks. I use VS Code notebooks now, and it just asks you to press the Enter key to proceed.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tokens = gpt2_tokenizer([example.prompt + ' ' + completion\n",
    "                             for example in wsc_examples\n",
    "                             for completion in example.completions])\n",
    "num_tokens = sum(len(tokens) for tokens in all_tokens['input_ids'])\n",
    "cost_per_1k_tokens = 0.02 ## https://openai.com/api/pricing/\n",
    "cost = round(num_tokens * cost_per_1k_tokens / 1_000, 2)\n",
    "\n",
    "output = input(f'The next cell will cost you ${cost}. Proceed?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing probs: 100%|██████████| 546/546 [00:12<00:00, 42.92it/s]\n"
     ]
    }
   ],
   "source": [
    "pred_probs = classify.predict_proba_examples(wsc_examples,\n",
    "                                             model='text-davinci-003')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We flattened/exploded the examples so that there's one record for each (example, option) pair. To go back to the original format, we just need to batch `pred_probs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_probs(probs: np.ndarray, batch_sizes):\n",
    "    pred_probs_unnorm = np.array(list(batch_variable(probs[:,0], batch_sizes)))\n",
    "    return pred_probs_unnorm / pred_probs_unnorm.sum(axis=1, keepdims=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For WSC, the scoring metric is accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8901098901098901"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_sizes = wsc_df['options'].apply(len) ## ik they're all 2\n",
    "pred_probs_norm = process_probs(pred_probs, batch_sizes)\n",
    "(pred_probs_norm.argmax(axis=1) == wsc_df['label']).mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This roughly matches the performance in the GPT-3 paper (section 3.4). I guess there wasn't much to learn from this b/c we're both basically using the same method. Nice to see that the code works I guess :-)\n",
    "\n",
    "For transparency, some of the WSC examples were included in GPT-3's training data. The authors [studied this contamination](https://arxiv.org/pdf/2005.14165.pdf#page=31&zoom=100,96,89) and found that isn't much of an issue for WSC in particular."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While we're were, let's see how `text-curie-001` performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing probs: 100%|██████████| 546/546 [00:07<00:00, 75.01it/s]\n"
     ]
    }
   ],
   "source": [
    "pred_probs_curie = classify.predict_proba_examples(wsc_examples,\n",
    "                                                   model='text-curie-001')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8131868131868132"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_probs_norm_curie = process_probs(pred_probs_curie, batch_sizes)\n",
    "(pred_probs_norm_curie.argmax(axis=1) == wsc_df['label']).mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "18983e9e827802b63835b8dbc18d4f8a4ebd5dd283f63362764c2c714492b89c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
